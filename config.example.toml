# SnapRAG Configuration Example
# Copy this file to config.toml and update with your settings

[database]
# PostgreSQL connection URL
# Format: postgresql://username:password@host:port/database
url = "postgresql://snaprag:your-password@localhost/snaprag"
max_connections = 100
# For CLI usage: set min_connections=2 for faster startup
# For API server: set min_connections=10-20 for better concurrency
min_connections = 2
connection_timeout = 60
slow_query_threshold_secs = 1.5

[logging]
level = "info"
backtrace = true

[embeddings]
dimension = 384
model = "bge-small-en-v1.5"
endpoint = "http://localhost:11434"  # Default Ollama port
provider = "ollama"  # Options: "ollama", "openai"
# api_key = "sk-your-api-key"  # Only needed for OpenAI provider

# Batch processing configuration (adjust based on GPU/CPU capacity)
# For CPU-only: batch_size=100-200, parallel_tasks=5-10
# For GPU (Tesla V100): batch_size=500-1000, parallel_tasks=100-200
batch_size = 500          # Number of items to fetch from DB per batch
parallel_tasks = 100      # Number of concurrent embedding requests

[performance]
enable_vector_indexes = true
vector_index_lists = 100

[sync]
# Snapchain endpoints (HTTP for REST API, gRPC for streaming)
snapchain_http_endpoint = "http://localhost:3381"
snapchain_grpc_endpoint = "http://localhost:3383"
enable_realtime_sync = true
enable_historical_sync = true
historical_sync_from_event_id = 0
batch_size = 500
sync_interval_ms = 50

# Shard IDs to sync:
# 0 = Block shard (coordinator, contains shard witnesses and global state)
# 1,2 = User shards (contain actual user transactions and messages)
shard_ids = [1, 2]

[llm]
# LLM endpoint for RAG queries
# Ollama default: http://localhost:11434
# Remote: http://your-server:port
llm_endpoint = "http://localhost:11434"
llm_key = "ollama"
llm_model = "gemma3:27b"

[cache]
# API caching configuration (uses Redis)
enabled = true
# Profile cache TTL in seconds (default: 1 hour)
profile_ttl_secs = 3600
# Social analysis cache TTL in seconds (default: 1 hour)  
social_ttl_secs = 3600
# Enable cache statistics
enable_stats = true

[redis]
# Redis configuration (required for cache and job queue)
url = "redis://127.0.0.1:6379"
# Namespace/prefix for keys (e.g. "snaprag:")
namespace = "snaprag:"
# Default TTL for cached API payloads (seconds). Target: 30 days
default_ttl_secs = 2592000
# Stale threshold for async refresh trigger (seconds). Target: 5 minutes
stale_threshold_secs = 300
# PubSub channel for refresh notifications
refresh_channel = "snaprag.refresh"

[x402]
# x402 payment configuration (optional, for paid API access)
# Payment address - where USDC payments will be sent
# Use burn address (0x0) to destroy payments, or your address to receive them
payment_address = "0x0000000000000000000000000000000000000000"
# Use testnet (base-sepolia) - x402.org/facilitator only supports testnet currently
use_testnet = true
# Enable payment by default
enabled = false
# Facilitator URL for payment verification
# Default: https://x402.org/facilitator (x402.org facilitator service)
facilitator_url = "https://x402.org/facilitator"
# RPC endpoint for blockchain verification (optional)
# If not set, will use default RPC for the selected network
# rpc_url = "https://sepolia.base.org"

# MBTI personality analysis configuration
[mbti]
# Analysis method: "rulebased", "machinelearning", or "ensemble"
# - rulebased: Uses behavioral patterns and social graph analysis (default, no extra dependencies)
# - machinelearning: Uses BERT + MLP neural networks (requires ml-mbti feature and trained models)
# - ensemble: Combines both methods for best accuracy (requires ml-mbti feature)
method = "rulebased"

# Use LLM for enhanced analysis (when available)
use_llm = false
